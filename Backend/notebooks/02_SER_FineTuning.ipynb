{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025514b3-2ed4-4750-8812-72d80436a3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import AutoProcessor, AutoModelForAudioClassification\n",
    "\n",
    "from datasets import load_dataset, Audio # <-- Key new imports\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import time\n",
    "import copy\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.metrics import accuracy_score, f1_score # For better metrics\n",
    "\n",
    "print(\"All libraries imported.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d018271-4cb2-4cac-84ef-50b47e011aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Setup Device ---\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# --- 2. Define Model Name ---\n",
    "model_name = \"ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition\"\n",
    "\n",
    "# --- 3. Define Data Paths ---\n",
    "DATA_DIR = '../data/MELD_processed/'\n",
    "TRAIN_FILE = os.path.join(DATA_DIR, 'train_text.csv')\n",
    "VAL_FILE = os.path.join(DATA_DIR, 'dev_text.csv')\n",
    "TEST_FILE = os.path.join(DATA_DIR, 'test_text.csv') # We'll load this later for final testing\n",
    "\n",
    "print(f\"Train file: {TRAIN_FILE}\")\n",
    "print(f\"Val file: {VAL_FILE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aca4031-f2e7-4779-aed7-f83798bde85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 4. Load CSV metadata ---\n",
    "data_files = {\n",
    "    \"train\": TRAIN_FILE,\n",
    "    \"val\": VAL_FILE\n",
    "}\n",
    "dataset = load_dataset(\"csv\", data_files=data_files)\n",
    "\n",
    "# --- 5. Cast audio column ---\n",
    "# WE ARE REMOVING THE .cast_column() LINE TO AVOID THE torchcodec ERROR\n",
    "# dataset = dataset.cast_column(\"audio_path\", Audio(sampling_rate=16000))\n",
    "\n",
    "# --- 6. Rename columns and get labels ---\n",
    "dataset = dataset.rename_column(\"emotion\", \"label\")\n",
    "\n",
    "# --- Convert the 'label' column (strings) into a ClassLabel object ---\n",
    "print(\"Encoding labels...\")\n",
    "dataset = dataset.class_encode_column(\"label\")\n",
    "\n",
    "# --- Get the list of labels ---\n",
    "labels = dataset[\"train\"].features[\"label\"].names\n",
    "num_labels = len(labels)\n",
    "\n",
    "# --- Create the dictionaries manually ---\n",
    "label2id = {label: i for i, label in enumerate(labels)}\n",
    "id2label = {i: label for i, label in enumerate(labels)}\n",
    "\n",
    "print(f\"Loaded dataset with {num_labels} labels:\")\n",
    "print(labels)\n",
    "print(f\"\\nExample of label2id: {label2id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd608a94-ddf7-4c0b-bd02-7d02c70a3760",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoFeatureExtractor, AutoModelForAudioClassification\n",
    "\n",
    "# --- 7. Load Processor & Model ---\n",
    "print(f\"Loading processor and model for: {model_name}...\")\n",
    "\n",
    "# --- THIS IS THE FIX ---\n",
    "# Use AutoFeatureExtractor, as this model doesn't have a text tokenizer\n",
    "processor = AutoFeatureExtractor.from_pretrained(model_name)\n",
    "# ---------------------\n",
    "\n",
    "model = AutoModelForAudioClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=num_labels,      # Pass our 7 Labels\n",
    "    label2id=label2id,          # Pass our new mappings\n",
    "    id2label=id2label,\n",
    "    use_safetensors=True,\n",
    "    ignore_mismatched_sizes=True  # <-- ADD THIS LINE TO FIX THE ERROR\n",
    ").to(device) # Move model to GPU\n",
    "\n",
    "print(\"‚úÖ Processor and model loaded successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb2b851-d913-4c29-81a7-a06b988521c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import librosa # <-- Make sure to import librosa\n",
    "\n",
    "# --- 8. Preprocessing Function ---\n",
    "# This function will be applied to every audio file\n",
    "def preprocess_function(batch):\n",
    "    \n",
    "    # --- THIS IS THE FIX ---\n",
    "    # Manually load audio files using librosa\n",
    "    audio_arrays = []\n",
    "    for path in batch[\"audio_path\"]:\n",
    "        y, sr = librosa.load(path, sr=16000) # Load and resample\n",
    "        audio_arrays.append(y)\n",
    "    # -----------------------\n",
    "\n",
    "    # The processor converts the audio arrays into numerical inputs\n",
    "    processed_batch = processor(\n",
    "        audio_arrays, # <-- Pass the loaded audio arrays\n",
    "        sampling_rate=16000,\n",
    "        truncation=True, # Truncate long audio files\n",
    "        padding=\"longest\", # Pad shorter files to be the same length\n",
    "        max_length=80000 # Max length = 5 seconds (16000 * 5)\n",
    "    )\n",
    "    \n",
    "    # The 'label' is already an integer, so we just pass it along\n",
    "    processed_batch[\"label\"] = batch[\"label\"]\n",
    "    return processed_batch\n",
    "\n",
    "# --- 9. Apply Preprocessing ---\n",
    "print(\"Applying preprocessing to the dataset (using librosa)...\")\n",
    "print(\"This may take a few minutes...\")\n",
    "\n",
    "# .map() applies the function to all examples. batched=True makes it fast.\n",
    "processed_dataset = dataset.map(\n",
    "    preprocess_function,\n",
    "    batched=True,\n",
    "    batch_size=100 # Process in chunks of 100\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Preprocessing complete.\")\n",
    "print(processed_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a8e007-811f-4b89-8df1-f6c1aff5a74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from dataclasses import dataclass\n",
    "from transformers.feature_extraction_utils import BatchFeature\n",
    "import torch.optim as optim\n",
    "\n",
    "# --- 10. Define Custom Data Collator ---\n",
    "# This class fixes the \"KeyError: 'label'\"\n",
    "@dataclass\n",
    "class CustomAudioDataCollator:\n",
    "    processor: any\n",
    "    padding: bool = True\n",
    "    \n",
    "    def __call__(self, features):\n",
    "        # 'features' is a list of dicts: [{'input_values': ..., 'label': ...}, ...]\n",
    "        \n",
    "        # 1. Separate the labels from the features\n",
    "        labels = [feature.pop(\"label\") for feature in features]\n",
    "        \n",
    "        # 2. Use the processor's built-in padding for the rest\n",
    "        # This will correctly pad 'input_values' and 'attention_mask'\n",
    "        batch = processor.pad(\n",
    "            features,\n",
    "            padding=self.padding,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        \n",
    "        # 3. Add the labels back into the batch, but as a tensor\n",
    "        batch[\"labels\"] = torch.tensor(labels) # Note: 'labels' (plural)\n",
    "        \n",
    "        return batch\n",
    "\n",
    "# --- 11. Initialize the Collator, Optimizer, and Loss ---\n",
    "data_collator = CustomAudioDataCollator(processor=processor, padding=True)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=3e-5)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "print(\"‚úÖ Custom Collator, Optimizer, and Loss defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "008ac471-a16e-4914-bc38-49a668454bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import copy\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "from torch.amp import autocast, GradScaler\n",
    "import numpy as np\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# --- 10. Define Optimizer and Loss ---\n",
    "optimizer = optim.AdamW(model.parameters(), lr=3e-5)\n",
    "\n",
    "# --- NEW: CALCULATE CLASS WEIGHTS TO FIX IMBALANCE ---\n",
    "# Get all training labels as a NumPy array (this is more stable)\n",
    "train_labels = np.array(processed_dataset[\"train\"][\"label\"])\n",
    "# Get unique class names (in order)\n",
    "class_names = processed_dataset[\"train\"].features[\"label\"].names\n",
    "\n",
    "# --- THIS IS THE FIX ---\n",
    "# Instead of np.unique(train_labels), we will manually create the list\n",
    "# of classes, which we know is [0, 1, 2, 3, 4, 5, 6]\n",
    "classes_list = np.arange(len(class_names))\n",
    "# -----------------------\n",
    "\n",
    "# Calculate weights\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=classes_list,  # <-- PASS THE CORRECT, FULL LIST\n",
    "    y=train_labels\n",
    ")\n",
    "# Convert weights to a PyTorch tensor and move to GPU\n",
    "class_weights = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
    "\n",
    "print(f\"Class weights: {class_weights}\")\n",
    "print(f\"Applying weights to: {class_names}\")\n",
    "\n",
    "# Pass the weights to the loss function\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "# ----------------------------------------------------\n",
    "\n",
    "print(\"‚úÖ Optimizer and Weighted Loss defined.\")\n",
    "\n",
    "# --- 11. Create DataLoaders (using batch_size=4) ---\n",
    "processed_dataset.set_format(type=\"torch\", columns=[\"input_values\", \"attention_mask\", \"label\"])\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    processed_dataset[\"train\"],\n",
    "    shuffle=True,\n",
    "    batch_size=4 # <-- Use batch_size 4\n",
    ")\n",
    "val_dataloader = DataLoader(\n",
    "    processed_dataset[\"val\"],\n",
    "    batch_size=4 # <-- Use batch_size 4\n",
    ")\n",
    "\n",
    "dataloaders = {\"train\": train_dataloader, \"val\": val_dataloader}\n",
    "dataset_sizes = {\"train\": len(processed_dataset[\"train\"]), \"val\": len(processed_dataset[\"val\"])}\n",
    "print(\"‚úÖ DataLoaders created successfully (batch_size=4).\")\n",
    "\n",
    "# --- 12. Define train_model function ---\n",
    "def train_model(model, criterion, optimizer, num_epochs=3):\n",
    "    since = time.time()\n",
    "    scaler = GradScaler('cuda')\n",
    "    accumulation_steps = 4 # Effective batch size = 4 * 4 = 16\n",
    "    \n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_f1 = 0.0 \n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'\\n--- Epoch {epoch+1}/{num_epochs} ---')\n",
    "        print('-' * 20)\n",
    "\n",
    "        for phase in ['train', 'val']:\n",
    "            model.train(phase == 'train')\n",
    "            running_loss, all_preds, all_labels = 0.0, [], []\n",
    "\n",
    "            for i, batch in enumerate(tqdm(dataloaders[phase], desc=f\"{phase.title()} Batches\", leave=False)):\n",
    "                input_values = batch['input_values'].to(device)\n",
    "                attention_mask = batch['attention_mask'].to(device)\n",
    "                labels = batch['label'].to(device) \n",
    "\n",
    "                with autocast('cuda', dtype=torch.float16):\n",
    "                    outputs = model(input_values=input_values, attention_mask=attention_mask)\n",
    "                    logits = outputs.logits\n",
    "                    loss = criterion(logits, labels) # Criterion now uses weights\n",
    "                    if phase == 'train':\n",
    "                        loss = loss / accumulation_steps\n",
    "\n",
    "                if phase == 'train':\n",
    "                    scaler.scale(loss).backward()\n",
    "                    if (i + 1) % accumulation_steps == 0 or (i + 1) == len(dataloaders[phase]):\n",
    "                        scaler.step(optimizer)\n",
    "                        scaler.update()\n",
    "                        optimizer.zero_grad(set_to_none=True)\n",
    "                else:\n",
    "                    pass \n",
    "\n",
    "                running_loss += loss.item() * input_values.size(0)\n",
    "                preds = torch.argmax(logits, dim=1)\n",
    "                all_preds.extend(preds.detach().cpu().numpy())\n",
    "                all_labels.extend(labels.detach().cpu().numpy())\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = accuracy_score(all_labels, all_preds)\n",
    "            epoch_f1 = f1_score(all_labels, all_preds, average=\"weighted\")\n",
    "\n",
    "            print(f\"{phase.capitalize()} ‚Üí Loss: {epoch_loss:.4f} | Acc: {epoch_acc:.4f} | F1: {epoch_f1:.4f}\")\n",
    "\n",
    "            if phase == 'val' and epoch_f1 > best_f1:\n",
    "                best_f1 = epoch_f1\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                print(f\"‚ú® New best val F1: {best_f1:.4f}\")\n",
    "\n",
    "    total_time = time.time() - since\n",
    "    print(f\"\\nüèÅ Training complete in {total_time/60:.1f} min | Best F1: {best_f1:.4f}\")\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model\n",
    "\n",
    "# --- 13. START TRAINING ---\n",
    "print(\"‚öôÔ∏è Starting fast fine-tuning loop (with weighted loss)...\")\n",
    "model_ft = train_model(model, criterion, optimizer, num_epochs=3)\n",
    "\n",
    "# --- 14. Save Model ---\n",
    "SAVE_PATH = \"../models/ser_model_finetuned_weighted.pth\" # New save name\n",
    "os.makedirs(os.path.dirname(SAVE_PATH), exist_ok=True)\n",
    "torch.save(model_ft.state_dict(), SAVE_PATH)\n",
    "print(f\"\\n‚úÖ Training Finished! Model saved to: {SAVE_PATH}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Trisense V2)",
   "language": "python",
   "name": "trisense_v2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
