{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#---cell-1\n",
        "# --- Download and Save MELD Persistently to Google Drive ---\n",
        "\n",
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "# 1. Mount Google Drive\n",
        "print(\"Mounting Google Drive...\")\n",
        "drive.mount('/content/drive')\n",
        "print(\"Google Drive mounted successfully!\")\n",
        "\n",
        "# 2. Define the path in your Google Drive where you want to save MELD\n",
        "#    You can change 'My Drive/MELD_Dataset' to whatever you prefer.\n",
        "#    The folder will be created if it doesn't exist.\n",
        "drive_save_path = '/content/drive/My Drive/MELD_Dataset'\n",
        "os.makedirs(drive_save_path, exist_ok=True)\n",
        "print(f\"Data will be saved in: {drive_save_path}\")\n",
        "\n",
        "# 3. Change the current working directory TO your Google Drive folder\n",
        "os.chdir(drive_save_path)\n",
        "print(f\"Current working directory changed to: {os.getcwd()}\") # Verify we are in the Drive folder\n",
        "\n",
        "# 4. Download the MELD Raw video file DIRECTLY into the Drive folder\n",
        "#    Only run this if the file doesn't already exist!\n",
        "meld_zip_file = 'MELD.Raw.tar.gz'\n",
        "meld_raw_folder = 'MELD.Raw' # This is the folder created after extraction\n",
        "\n",
        "if not os.path.exists(meld_zip_file) and not os.path.exists(meld_raw_folder):\n",
        "    print(f\"Downloading {meld_zip_file} (10GB) to Google Drive...\")\n",
        "    print(\"This will take a significant amount of time, depending on Drive/Colab speed.\")\n",
        "    # Use !wget to download directly here\n",
        "    !wget -O '{meld_zip_file}' http://web.eecs.umich.edu/~mihalcea/downloads/MELD.Raw.tar.gz\n",
        "    print(\"Download complete!\")\n",
        "elif os.path.exists(meld_zip_file):\n",
        "    print(f\"'{meld_zip_file}' already exists in Google Drive. Skipping download.\")\n",
        "elif os.path.exists(meld_raw_folder):\n",
        "     print(f\"Extracted folder '{meld_raw_folder}' already exists. Skipping download and extraction.\")\n",
        "\n",
        "# 5. Extract the file DIRECTLY in the Drive folder\n",
        "#    Only run this if the zip file exists AND the extracted folder doesn't\n",
        "if os.path.exists(meld_zip_file) and not os.path.exists(meld_raw_folder):\n",
        "    print(f\"Extracting {meld_zip_file} within Google Drive...\")\n",
        "    print(\"This will also take a while.\")\n",
        "    # Use !tar to extract here\n",
        "    !tar -xzf '{meld_zip_file}'\n",
        "    print(\"Extraction complete!\")\n",
        "    # Optional: Remove the large zip file after extraction to save Drive space\n",
        "    # os.remove(meld_zip_file)\n",
        "    # print(f\"Removed '{meld_zip_file}' to save space.\")\n",
        "elif not os.path.exists(meld_zip_file) and os.path.exists(meld_raw_folder):\n",
        "     print(f\"Extracted folder '{meld_raw_folder}' already exists. Nothing to extract.\")\n",
        "elif not os.path.exists(meld_zip_file) and not os.path.exists(meld_raw_folder):\n",
        "    print(\"Neither zip file nor extracted folder found. Please check download step.\")\n",
        "\n",
        "\n",
        "print(\"\\n--- MELD dataset is now stored persistently in Google Drive ---\")\n",
        "print(f\"Video files should be in: {os.path.join(drive_save_path, meld_raw_folder)}\")\n",
        "\n",
        "# IMPORTANT: Change back to the default Colab directory if needed for later steps\n",
        "# os.chdir('/content')\n",
        "# print(f\"Current working directory changed back to: {os.getcwd()}\")"
      ],
      "metadata": {
        "id": "u72bEVZKbTiG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#---cell-2\n",
        "# --- Step 1: Install All Libraries ---\n",
        "# (This cell combines all the libraries we need)\n",
        "\n",
        "# For loading Hugging Face models and datasets\n",
        "!pip install transformers datasets\n",
        "\n",
        "# For deep learning\n",
        "!pip install torch\n",
        "\n",
        "# For video/image processing\n",
        "!pip install opencv-python-headless\n",
        "\n",
        "# For detecting faces\n",
        "!pip install mtcnn"
      ],
      "metadata": {
        "id": "jc3b7xhWUe5l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XMv0yYhDGzdD"
      },
      "outputs": [],
      "source": [
        "#---cell-3\n",
        "!pip install huggingface_hub --quiet\n",
        "\n",
        "from huggingface_hub import login\n",
        "# paste your token when prompted\n",
        "login()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#---cell-4\n",
        "import os\n",
        "os.environ[\"HF_TOKEN\"] = \"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\"   # replace with your token\n",
        "\n",
        "from huggingface_hub import login\n",
        "login(token=os.environ[\"HF_TOKEN\"])\n"
      ],
      "metadata": {
        "id": "QK0uhWcMUcPh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#---cell-5\n",
        "# (Run your actual Step 2 cell)\n",
        "from transformers import AutoImageProcessor, AutoModelForImageClassification\n",
        "import torch\n",
        "\n",
        "model_name = \"trpakov/vit-face-expression\"\n",
        "processor = AutoImageProcessor.from_pretrained(model_name)\n",
        "model = AutoModelForImageClassification.from_pretrained(model_name)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "model.eval()\n",
        "print(f\"Model {model_name} loaded to {device}\")"
      ],
      "metadata": {
        "id": "LW_LkHjzZwEq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#---cell-6\n",
        "import os\n",
        "\n",
        "meld_path = '/content/drive/My Drive/MELD_Dataset/MELD.Raw'\n",
        "for root, dirs, files in os.walk(meld_path):\n",
        "    print(root)\n",
        "    for name in files[:5]:  # only show first few files per folder\n",
        "        print(\"   \", name)\n"
      ],
      "metadata": {
        "id": "IpmU_9WOzoHv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#---cell-7\n",
        "# --- Step 4 (Revised): Extract Inner Archives & Load CSVs ---\n",
        "\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# Define the path where MELD.Raw was extracted in your Google Drive\n",
        "meld_raw_path = '/content/drive/My Drive/MELD_Dataset/MELD.Raw'\n",
        "print(f\"Looking for data in: {meld_raw_path}\")\n",
        "\n",
        "# Change directory to the MELD.Raw folder\n",
        "try:\n",
        "    os.chdir(meld_raw_path)\n",
        "    print(f\"Changed directory to: {os.getcwd()}\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"ERROR: Directory not found: {meld_raw_path}\")\n",
        "    print(\"Please ensure Step 3 completed successfully and the path is correct.\")\n",
        "\n",
        "# --- Extract Inner Archives ---\n",
        "archives = {\n",
        "    \"train\": \"train.tar.gz\",\n",
        "    \"dev\": \"dev.tar.gz\",\n",
        "    \"test\": \"test.tar.gz\" # Note: The test videos might be in 'output_repeated_splits_test' folder from initial extract\n",
        "}\n",
        "\n",
        "# Define expected output folders after extraction\n",
        "output_folders = {\n",
        "    \"train\": \"train_splits\", # Check exact name after extraction\n",
        "    \"dev\": \"dev_splits\",     # Check exact name after extraction\n",
        "    \"test\": \"output_repeated_splits_test\" # This often seems to be the test folder name\n",
        "}\n",
        "\n",
        "\n",
        "for split, archive_name in archives.items():\n",
        "    output_folder = output_folders[split]\n",
        "    if os.path.exists(archive_name) and not os.path.exists(output_folder):\n",
        "        print(f\"Extracting {archive_name}...\")\n",
        "        # Use '--one-top-level' if available to prevent tarbomb, adjust folder name if needed\n",
        "        !tar -xzf {archive_name}\n",
        "        # Check if extraction created the expected folder, might need adjustment\n",
        "        if os.path.exists(output_folder):\n",
        "             print(f\"✅ {archive_name} extracted successfully to {output_folder}!\")\n",
        "        else:\n",
        "             # If extraction didn't create the specific folder, list contents to see what was made\n",
        "             print(f\"Extraction of {archive_name} finished. Checking contents...\")\n",
        "             !ls -ld */ # List only directories\n",
        "    elif not os.path.exists(archive_name) and os.path.exists(output_folder):\n",
        "         print(f\"✅ {output_folder} already exists. Skipping extraction for {split}.\")\n",
        "    elif os.path.exists(archive_name) and os.path.exists(output_folder):\n",
        "         print(f\"✅ {output_folder} already exists. Skipping extraction for {split}.\")\n",
        "    elif split == 'test' and os.path.exists(output_folders['test']):\n",
        "         # Special check for test folder potentially already existing from first extraction\n",
        "         print(f\"✅ {output_folders['test']} already exists. Assuming test videos are present.\")\n",
        "    else:\n",
        "        # Only print warning if the archive is truly missing and output folder isn't there either\n",
        "        if not os.path.exists(output_folder):\n",
        "             print(f\"Warning: {archive_name} not found and {output_folder} doesn't exist.\")\n",
        "\n",
        "\n",
        "# --- Load CSV Files ---\n",
        "csv_files = {\n",
        "    \"train\": \"train_sent_emo.csv\", # Check if this is inside MELD.Raw or extracted train_splits\n",
        "    \"dev\": \"dev_sent_emo.csv\",\n",
        "    \"test\": \"test_sent_emo.csv\"\n",
        "}\n",
        "\n",
        "dataframes = {}\n",
        "\n",
        "print(\"\\nLoading CSV files...\")\n",
        "for split, csv_name in csv_files.items():\n",
        "    if os.path.exists(csv_name):\n",
        "        try:\n",
        "            dataframes[split] = pd.read_csv(csv_name)\n",
        "            print(f\"✅ Loaded {csv_name} successfully ({len(dataframes[split])} rows).\")\n",
        "        except Exception as e:\n",
        "            print(f\"ERROR loading {csv_name}: {e}\")\n",
        "    else:\n",
        "        # Try looking inside the split folder if it exists\n",
        "        split_folder = output_folders.get(split)\n",
        "        if split_folder and os.path.exists(os.path.join(split_folder, csv_name)):\n",
        "             try:\n",
        "                 dataframes[split] = pd.read_csv(os.path.join(split_folder, csv_name))\n",
        "                 print(f\"✅ Loaded {os.path.join(split_folder, csv_name)} successfully ({len(dataframes[split])} rows).\")\n",
        "             except Exception as e:\n",
        "                  print(f\"ERROR loading {os.path.join(split_folder, csv_name)}: {e}\")\n",
        "        else:\n",
        "            print(f\"Warning: {csv_name} not found in {meld_raw_path} or potential subdirectories.\")\n",
        "\n",
        "\n",
        "# --- Inspect the data ---\n",
        "if \"train\" in dataframes:\n",
        "    print(\"\\n--- First 5 rows of Training Data ---\")\n",
        "    print(dataframes[\"train\"].head())\n",
        "    print(\"\\n--- Training Data Info ---\")\n",
        "    dataframes[\"train\"].info()\n",
        "else:\n",
        "    print(\"\\nCould not load training data.\")\n",
        "\n",
        "# Optional: Change back to the main content directory if needed\n",
        "# os.chdir('/content')\n",
        "# print(f\"\\nChanged directory back to: {os.getcwd()}\")"
      ],
      "metadata": {
        "id": "7LEM3fOt2Vkq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#---cell-8\n",
        "!pip install lz4"
      ],
      "metadata": {
        "id": "FdkZ2dU0MFOj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#---cell-9\n",
        "# --- Step 5 (Debugging Version - Install lz4 inside): Check Paths and Process One Video ---\n",
        "\n",
        "import cv2\n",
        "# Import MTCNN later, after installing lz4\n",
        "# from mtcnn import MTCNN\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import os\n",
        "from datasets import Dataset, DatasetDict\n",
        "import torch\n",
        "\n",
        "# --- 1. Install lz4 ---\n",
        "print(\"Attempting to install lz4...\")\n",
        "!pip install lz4\n",
        "print(\"lz4 installation command finished.\")\n",
        "\n",
        "# --- 2. Verify Paths and Initialize Detector ---\n",
        "drive_base_path = '/content/drive/My Drive/MELD_Dataset/'\n",
        "meld_raw_path = os.path.join(drive_base_path, 'MELD.Raw')\n",
        "print(f\"\\nBase path for MELD.Raw: {meld_raw_path}\")\n",
        "\n",
        "print(\"\\nListing contents of MELD.Raw to verify folder names:\")\n",
        "try:\n",
        "    original_dir = os.getcwd()\n",
        "    os.chdir(meld_raw_path)\n",
        "    print(\"Contents:\")\n",
        "    !ls -l\n",
        "    os.chdir(original_dir)\n",
        "except FileNotFoundError:\n",
        "    print(f\"ERROR: Cannot access {meld_raw_path}. Please check the path.\")\n",
        "\n",
        "# --- UPDATE THESE FOLDER NAMES BASED ON THE `ls` OUTPUT ABOVE ---\n",
        "video_folders = {\n",
        "    \"train\": os.path.join(meld_raw_path, \"train_splits\"),\n",
        "    \"dev\": os.path.join(meld_raw_path, \"dev_splits_complete\"),\n",
        "    \"test\": os.path.join(meld_raw_path, \"output_repeated_splits_test\")\n",
        "}\n",
        "print(f\"\\nExpected video folders:\")\n",
        "print(f\"Train: {video_folders['train']}\")\n",
        "print(f\"Dev:   {video_folders['dev']}\")\n",
        "print(f\"Test:  {video_folders['test']}\")\n",
        "\n",
        "\n",
        "print(\"\\nImporting MTCNN and initializing face detector...\")\n",
        "try:\n",
        "    # Import MTCNN *after* installing lz4\n",
        "    from mtcnn import MTCNN\n",
        "    detector = MTCNN()\n",
        "    print(\"✅ MTCNN detector initialized.\")\n",
        "except ImportError:\n",
        "     print(f\"❌ ERROR: Failed to import MTCNN even after pip install.\")\n",
        "     detector = None\n",
        "except Exception as e:\n",
        "    print(f\"❌ ERROR initializing MTCNN: {e}\")\n",
        "    # Check if it's the lz4 error again specifically\n",
        "    if 'LZ4' in str(e):\n",
        "         print(\"The LZ4 error persists. This is very unusual.\")\n",
        "    detector = None\n",
        "\n",
        "# Reload processor if needed\n",
        "if 'processor' not in globals():\n",
        "     print(\"Reloading processor...\")\n",
        "     from transformers import AutoImageProcessor\n",
        "     processor_name = \"trpakov/vit-face-expression\"\n",
        "     processor = AutoImageProcessor.from_pretrained(processor_name)\n",
        "     print(\"Processor reloaded.\")\n",
        "\n",
        "# --- 3. Manually Process One Example ---\n",
        "print(\"\\n--- Attempting to process one training example manually ---\")\n",
        "\n",
        "# Check if detector initialized successfully\n",
        "if detector and \"train\" in dataframes:\n",
        "    example = dataframes[\"train\"].iloc[0].to_dict()\n",
        "    split_name = \"train\"\n",
        "    print(f\"Using example: Dia_ID={example.get('Dialogue_ID')}, Utt_ID={example.get('Utterance_ID')}, Emotion={example.get('Emotion')}\")\n",
        "\n",
        "    try:\n",
        "        # --- [ The rest of the manual processing code remains the same ] ---\n",
        "        # --- [ Find video, open, read frame, detect face, crop, process ] ---\n",
        "        dialogue_id = example['Dialogue_ID']\n",
        "        utterance_id = example['Utterance_ID']\n",
        "        video_filename = f\"dia{dialogue_id}_utt{utterance_id}.mp4\"\n",
        "        print(f\"Constructed filename: {video_filename}\")\n",
        "\n",
        "        current_video_folder = video_folders.get(split_name)\n",
        "        if not current_video_folder:\n",
        "             raise ValueError(f\"Video folder path for split '{split_name}' is not defined correctly.\")\n",
        "        print(f\"Looking in folder: {current_video_folder}\")\n",
        "\n",
        "        full_video_path = os.path.join(current_video_folder, video_filename)\n",
        "        print(f\"Full video path: {full_video_path}\")\n",
        "\n",
        "        print(f\"Checking if video file exists at path...\")\n",
        "        if not os.path.exists(full_video_path):\n",
        "            print(f\"❌ ERROR: Video file NOT FOUND at {full_video_path}\")\n",
        "            if os.path.exists(current_video_folder):\n",
        "                 !ls -l '{current_video_folder}' | head -10\n",
        "            else:\n",
        "                 print(f\"Folder {current_video_folder} does not exist.\")\n",
        "        else:\n",
        "            print(f\"✅ Video file found!\")\n",
        "            print(\"Attempting to open video with OpenCV...\")\n",
        "            cap = cv2.VideoCapture(full_video_path)\n",
        "            if not cap.isOpened(): print(f\"❌ ERROR: Could not open video file {full_video_path}\")\n",
        "            else:\n",
        "                print(\"✅ Video opened successfully.\")\n",
        "                frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "                middle_frame_idx = frame_count // 2\n",
        "                print(f\"Total frames: {frame_count}. Reading frame index: {middle_frame_idx}\")\n",
        "                cap.set(cv2.CAP_PROP_POS_FRAMES, middle_frame_idx)\n",
        "                ret, frame = cap.read(); cap.release()\n",
        "                if not ret or frame is None: print(f\"❌ ERROR: Could not read middle frame from video.\")\n",
        "                else:\n",
        "                    print(f\"✅ Frame read successfully (shape: {frame.shape}).\")\n",
        "                    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "                    print(\"Attempting to detect face with MTCNN...\")\n",
        "                    faces = detector.detect_faces(frame_rgb) # Use detector here\n",
        "                    if not faces: print(f\"❌ ERROR: No face detected in the frame.\")\n",
        "                    else:\n",
        "                        print(f\"✅ Face detected! Details: {faces[0]['box']}\")\n",
        "                        bounding_box = faces[0]['box']; x, y, w, h = bounding_box; padding = 20\n",
        "                        x1, y1 = max(0, x - padding), max(0, y - padding)\n",
        "                        x2, y2 = min(frame_rgb.shape[1], x + w + padding), min(frame_rgb.shape[0], y + h + padding)\n",
        "                        print(\"Attempting to crop face...\")\n",
        "                        face_crop = frame_rgb[y1:y2, x1:x2]\n",
        "                        if face_crop.size == 0: print(f\"❌ ERROR: Face crop resulted in an empty image.\")\n",
        "                        else:\n",
        "                            print(f\"✅ Face cropped successfully (shape: {face_crop.shape}).\")\n",
        "                            face_image = Image.fromarray(face_crop)\n",
        "                            print(\"Attempting to process face image with processor...\")\n",
        "                            try:\n",
        "                                inputs = processor(images=face_image, return_tensors=\"pt\")\n",
        "                                pixel_values = inputs['pixel_values'].squeeze(0)\n",
        "                                print(f\"✅ Image processed successfully! Tensor shape: {pixel_values.shape}\")\n",
        "                                emotion_map = {'neutral': 0, 'surprise': 1, 'fear': 2, 'sadness': 3, 'joy': 4, 'disgust': 5, 'anger': 6}\n",
        "                                emotion_str = example.get('Emotion', 'unknown').lower()\n",
        "                                emotion_label = emotion_map.get(emotion_str, -1)\n",
        "                                print(f\"Original emotion: '{example.get('Emotion')}', Mapped label: {emotion_label}\")\n",
        "                                print(\"\\n--- ✅ MANUAL PREPROCESSING SUCCEEDED FOR ONE EXAMPLE ---\")\n",
        "                            except Exception as proc_e: print(f\"❌ ERROR: Processor failed on face image: {proc_e}\")\n",
        "    except Exception as e:\n",
        "        print(f\"--- ❌ An unexpected error occurred during manual processing ---\")\n",
        "        print(f\"Error: {e}\")\n",
        "\n",
        "elif not detector:\n",
        "    print(\"MTCNN detector failed to initialize. Cannot proceed with processing.\")\n",
        "else:\n",
        "    print(\"Could not load 'train' dataframe for testing.\")"
      ],
      "metadata": {
        "id": "m1S2vVxKIBN-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#---cell-10\n",
        "# --- Step 5: Define and Apply Video Preprocessing ---\n",
        "\n",
        "import cv2\n",
        "from mtcnn import MTCNN\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import os\n",
        "from datasets import Dataset, DatasetDict # Import Dataset classes\n",
        "import torch # Ensure torch is imported\n",
        "\n",
        "# --- 1. Re-define paths and initialize detector ---\n",
        "# (In case the session restarted or variables were lost)\n",
        "drive_base_path = '/content/drive/My Drive/MELD_Dataset/'\n",
        "meld_raw_path = os.path.join(drive_base_path, 'MELD.Raw')\n",
        "print(f\"Base path for videos: {meld_raw_path}\")\n",
        "\n",
        "print(\"Initializing MTCNN face detector...\")\n",
        "try:\n",
        "    detector = MTCNN()\n",
        "    print(\"MTCNN detector initialized.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error initializing MTCNN: {e}. Please ensure mtcnn library is installed.\")\n",
        "    # Add exit or raise error if detector is crucial\n",
        "\n",
        "# Define the expected video subfolder names\n",
        "video_folders = {\n",
        "    \"train\": os.path.join(meld_raw_path, \"train_splits\"),\n",
        "    \"dev\": os.path.join(meld_raw_path, \"dev_splits_complete\"), # Adjust if needed\n",
        "    \"test\": os.path.join(meld_raw_path, \"output_repeated_splits_test\") # Adjust if needed\n",
        "}\n",
        "\n",
        "# --- 2. The Preprocessing Function ---\n",
        "# (Make sure the processor variable is still loaded from Step 2)\n",
        "# Check if processor exists, otherwise reload it (example)\n",
        "if 'processor' not in globals():\n",
        "     print(\"Reloading processor...\")\n",
        "     from transformers import AutoImageProcessor\n",
        "     processor_name = \"microsoft/resnet-50\" # Or the ViT one you loaded initially\n",
        "     processor = AutoImageProcessor.from_pretrained(processor_name)\n",
        "     print(\"Processor reloaded.\")\n",
        "\n",
        "\n",
        "def preprocess_video_frame(example):\n",
        "    \"\"\"\n",
        "    Finds video, extracts frame, detects/crops face, processes for model.\n",
        "    Uses Dialogue_ID and Utterance_ID to build the filename.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Construct filename: e.g., dia0_utt0.mp4\n",
        "        dialogue_id = example['Dialogue_ID']\n",
        "        utterance_id = example['Utterance_ID']\n",
        "        video_filename = f\"dia{dialogue_id}_utt{utterance_id}.mp4\"\n",
        "\n",
        "        # Determine which split folder to look in based on the dataframe source\n",
        "        # This requires knowing which split this example came from, map handles this.\n",
        "        # We'll determine the correct path inside the map function call later.\n",
        "        # For now, placeholder - full_video_path will be set later.\n",
        "        # We need the 'split_name' to be passed or inferred.\n",
        "\n",
        "        # *** Path construction moved inside the mapped function below ***\n",
        "\n",
        "        # --- Remaining steps from previous function ---\n",
        "        # 2. Open the video file (path needs to be determined by map)\n",
        "        # ... [rest of the function: open video, extract frame, detect face, crop, process, get label] ...\n",
        "        # ... Make sure to use the correct video path based on the split ...\n",
        "\n",
        "        # Placeholder return - actual logic needed\n",
        "        return {'pixel_values': None, 'label': -1, 'video_filename_used': video_filename, 'status': 'placeholder'}\n",
        "\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"ERROR processing example (Dia:{example.get('Dialogue_ID', 'N/A')}, Utt:{example.get('Utterance_ID', 'N/A')}): {e}\")\n",
        "        return {'pixel_values': None, 'label': -1, 'video_filename_used': 'error', 'status': 'error'}\n",
        "\n",
        "\n",
        "# --- 3. Convert Pandas DataFrames to Hugging Face Datasets ---\n",
        "print(\"\\nConverting pandas DataFrames to Datasets...\")\n",
        "raw_datasets = DatasetDict()\n",
        "successful_conversions = []\n",
        "for split in [\"train\", \"dev\", \"test\"]:\n",
        "    if split in dataframes:\n",
        "        try:\n",
        "            raw_datasets[split] = Dataset.from_pandas(dataframes[split])\n",
        "            print(f\"Successfully converted {split} DataFrame.\")\n",
        "            successful_conversions.append(split)\n",
        "        except Exception as e:\n",
        "            print(f\"Error converting {split} DataFrame: {e}\")\n",
        "    else:\n",
        "        print(f\"No DataFrame found for {split} split.\")\n",
        "\n",
        "print(f\"\\nRaw Datasets structure: {raw_datasets}\")\n",
        "\n",
        "\n",
        "# --- 4. Apply the Preprocessing Function using .map() ---\n",
        "\n",
        "# Define the updated preprocessing function that correctly uses the split info\n",
        "def map_preprocess_function(example, split_name):\n",
        "     \"\"\"\n",
        "     Wrapper for preprocess_video_frame that constructs the correct path.\n",
        "     \"\"\"\n",
        "     try:\n",
        "          dialogue_id = example['Dialogue_ID']\n",
        "          utterance_id = example['Utterance_ID']\n",
        "          video_filename = f\"dia{dialogue_id}_utt{utterance_id}.mp4\"\n",
        "\n",
        "          # Determine the correct video folder for the current split\n",
        "          current_video_folder = video_folders.get(split_name)\n",
        "          if not current_video_folder or not os.path.exists(current_video_folder):\n",
        "               # print(f\"Warning: Video folder for split '{split_name}' not found at {current_video_folder}\")\n",
        "               return {'pixel_values': None, 'label': -1, 'status': 'folder_not_found'}\n",
        "\n",
        "          full_video_path = os.path.join(current_video_folder, video_filename)\n",
        "\n",
        "          # --- Rest of the preprocessing logic ---\n",
        "          if not os.path.exists(full_video_path):\n",
        "              # print(f\"Warning: Video file not found at {full_video_path}\")\n",
        "              return {'pixel_values': None, 'label': -1, 'status': 'file_not_found'}\n",
        "\n",
        "          cap = cv2.VideoCapture(full_video_path)\n",
        "          if not cap.isOpened(): return {'pixel_values': None, 'label': -1, 'status': 'cant_open_video'}\n",
        "\n",
        "          frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "          middle_frame_idx = frame_count // 2\n",
        "          cap.set(cv2.CAP_PROP_POS_FRAMES, middle_frame_idx)\n",
        "          ret, frame = cap.read()\n",
        "          cap.release()\n",
        "\n",
        "          if not ret or frame is None: return {'pixel_values': None, 'label': -1, 'status': 'cant_read_frame'}\n",
        "\n",
        "          frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "          faces = detector.detect_faces(frame_rgb)\n",
        "\n",
        "          if not faces: return {'pixel_values': None, 'label': -1, 'status': 'no_face_detected'}\n",
        "\n",
        "          bounding_box = faces[0]['box']\n",
        "          x, y, w, h = bounding_box\n",
        "          padding = 20\n",
        "          x1, y1 = max(0, x - padding), max(0, y - padding)\n",
        "          x2, y2 = min(frame_rgb.shape[1], x + w + padding), min(frame_rgb.shape[0], y + h + padding)\n",
        "          face_crop = frame_rgb[y1:y2, x1:x2]\n",
        "\n",
        "          if face_crop.size == 0: return {'pixel_values': None, 'label': -1, 'status': 'empty_crop'}\n",
        "\n",
        "          face_image = Image.fromarray(face_crop)\n",
        "\n",
        "          try:\n",
        "               inputs = processor(images=face_image, return_tensors=\"pt\")\n",
        "               pixel_values = inputs['pixel_values'].squeeze(0)\n",
        "          except Exception as proc_e:\n",
        "               # print(f\"Processor error on {full_video_path}: {proc_e}\")\n",
        "               return {'pixel_values': None, 'label': -1, 'status': 'processor_error'}\n",
        "\n",
        "          # Get label (assuming 'Emotion' column exists and is string)\n",
        "          # Make sure the features are accessible - might need to load them if not part of Dataset\n",
        "          # For pandas-loaded data, we need the mapping explicitly\n",
        "          emotion_map = {'neutral': 0, 'surprise': 1, 'fear': 2, 'sadness': 3, 'joy': 4, 'disgust': 5, 'anger': 6}\n",
        "          emotion_str = example.get('Emotion', 'unknown').lower() # Handle potential missing/case issues\n",
        "          emotion_label = emotion_map.get(emotion_str, -1) # Default to -1 if unknown\n",
        "\n",
        "          if emotion_label == -1:\n",
        "               # print(f\"Warning: Unknown emotion '{example.get('Emotion')}' in {full_video_path}\")\n",
        "               pass # Keep label as -1, will filter later\n",
        "\n",
        "          return {'pixel_values': pixel_values, 'label': emotion_label, 'status': 'success'}\n",
        "\n",
        "     except Exception as e:\n",
        "          # print(f\"ERROR in map_preprocess_function for Dia:{example.get('Dialogue_ID', 'N/A')}, Utt:{example.get('Utterance_ID', 'N/A')}: {e}\")\n",
        "          return {'pixel_values': None, 'label': -1, 'status': 'unknown_error'}\n",
        "\n",
        "\n",
        "# Apply the mapping function to each split that was successfully converted\n",
        "processed_datasets = DatasetDict()\n",
        "num_proc = 1 # Use multiple CPU cores for faster processing if available in Colab\n",
        "\n",
        "print(f\"\\nApplying preprocessing function using {num_proc} processes (this will be slower)...\")\n",
        "for split_name in successful_conversions:\n",
        "    print(f\"Processing '{split_name}' split...\")\n",
        "    processed_datasets[split_name] = raw_datasets[split_name].map(\n",
        "        map_preprocess_function,\n",
        "        fn_kwargs={'split_name': split_name}, # Pass the split name to the function\n",
        "        batched=False, # Process one example at a time\n",
        "        num_proc=num_proc, # Use multiple cores\n",
        "        remove_columns=raw_datasets[split_name].column_names # Remove old columns\n",
        "    )\n",
        "    print(f\"Finished processing '{split_name}'.\")\n",
        "\n",
        "\n",
        "# --- 5. Filter out failed examples ---\n",
        "print(\"\\nFiltering out examples where preprocessing failed...\")\n",
        "filtered_datasets = DatasetDict()\n",
        "for split_name in processed_datasets:\n",
        "    # Keep only examples where pixel_values is not None and label is valid (>= 0)\n",
        "    filtered_datasets[split_name] = processed_datasets[split_name].filter(\n",
        "        lambda example: example['pixel_values'] is not None and example['label'] >= 0\n",
        "    )\n",
        "    # Also remove the 'status' column if it exists\n",
        "    if 'status' in filtered_datasets[split_name].column_names:\n",
        "         filtered_datasets[split_name] = filtered_datasets[split_name].remove_columns(['status'])\n",
        "\n",
        "    print(f\"'{split_name}' split: {len(processed_datasets[split_name])} processed -> {len(filtered_datasets[split_name])} valid examples.\")\n",
        "\n",
        "\n",
        "# --- 6. Set Format for PyTorch ---\n",
        "print(\"\\nSetting dataset format to PyTorch tensors...\")\n",
        "try:\n",
        "    filtered_datasets.set_format(\"torch\", columns=[\"pixel_values\", \"label\"])\n",
        "    print(\"Format set successfully.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error setting format: {e}\")\n",
        "\n",
        "# --- Final Check ---\n",
        "print(\"\\n--- Preprocessing Complete ---\")\n",
        "print(f\"Final dataset structure: {filtered_datasets}\")\n",
        "if \"train\" in filtered_datasets:\n",
        "    print(\"\\nFirst example from processed training set:\")\n",
        "    print(filtered_datasets[\"train\"][0])\n",
        "    print(f\"Label: {filtered_datasets['train'][0]['label']}\")\n",
        "    print(f\"Tensor shape: {filtered_datasets['train'][0]['pixel_values'].shape}\")\n",
        "else:\n",
        "    print(\"\\nNo valid training data after processing.\")"
      ],
      "metadata": {
        "id": "meriIc7ZMtX9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}